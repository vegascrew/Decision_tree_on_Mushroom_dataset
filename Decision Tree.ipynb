{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import math\n",
    "import operator\n",
    "from pprint import pprint\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def load_instances(filename):\n",
    "    instances=[]\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            new_instance = line.strip().split(',')\n",
    "            instances.append(new_instance)\n",
    "    return instances\n",
    "\n",
    "def entropy(instances, class_index=0, attribute_name=None, value_name=None):\n",
    "    num_instances = len(instances)\n",
    "    if num_instances <= 1:\n",
    "        return 0\n",
    "    value_counts = defaultdict(int)\n",
    "    for instance in instances:\n",
    "        value_counts[instance[class_index]] += 1\n",
    "    num_values = len(value_counts)\n",
    "    if num_values <= 1:\n",
    "        return 0\n",
    "    attribute_entropy = 0.0\n",
    "    if attribute_name:\n",
    "        print('entropy({}{}) = '.format(attribute_name, \n",
    "           '={}'.format(value_name) if value_name else ''))\n",
    "    for value in value_counts:\n",
    "        value_probability = value_counts[value] / num_instances\n",
    "        child_entropy = value_probability * math.log(value_probability, 2)\n",
    "        attribute_entropy -= child_entropy\n",
    "        if attribute_name:\n",
    "            print('  - p({0}) x log(p({0}), {1})  =  - {2:5.3f} x log({2:5.3f})  =  {3:5.3f}'.format(\n",
    "                value, num_values, value_probability, child_entropy))\n",
    "    if attribute_name:\n",
    "        print('  = {:5.3f}'.format(attribute_entropy))\n",
    "    return attribute_entropy\n",
    "\n",
    "\n",
    "def information_gain(instances, parent_index, class_index=0, attribute_name=False):\n",
    "    parent_entropy = entropy(instances, class_index, attribute_name)\n",
    "    child_instances = defaultdict(list)\n",
    "    for instance in instances:\n",
    "        child_instances[instance[parent_index]].append(instance)\n",
    "    children_entropy = 0.0\n",
    "    num_instances = len(instances)\n",
    "    for child_value in child_instances:\n",
    "        child_probability = len(child_instances[child_value]) / num_instances\n",
    "        children_entropy += child_probability * entropy(\n",
    "                 child_instances[child_value], class_index, attribute_name, child_value)\n",
    "    return parent_entropy - children_entropy\n",
    "\n",
    "def majority_value(instances, class_index=0):\n",
    "    class_counts = Counter([instance[class_index] for instance in instances])\n",
    "    return class_counts.most_common(1)[0][0]\n",
    "\n",
    "def choose_best_attribute_index(instances, candidate_attribute_indexes, class_index=0):\n",
    "    gains_and_indexes = sorted([(information_gain(instances, i), i) for i in candidate_attribute_indexes], \n",
    "                               reverse=True)\n",
    "    return gains_and_indexes[0][1]\n",
    "\n",
    "def split_instances(instances, attribute_index):\n",
    "    partitions = defaultdict(list)\n",
    "    for instance in instances:\n",
    "        partitions[instance[attribute_index]].append(instance)\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDecisionTree:\n",
    "\n",
    "    _tree = {}  \n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "            \n",
    "    def fit(self, \n",
    "            instances, \n",
    "            candidate_attribute_indexes=None,\n",
    "            target_attribute_index=0,\n",
    "            default_class=None):\n",
    "        if not candidate_attribute_indexes:\n",
    "            candidate_attribute_indexes = [i \n",
    "                                           for i in range(len(instances[0]))\n",
    "                                           if i != target_attribute_index]\n",
    "        self._tree = self._create_tree(instances,\n",
    "                                       candidate_attribute_indexes,\n",
    "                                       target_attribute_index,\n",
    "                                       default_class)\n",
    "        \n",
    "    def _create_tree(self,\n",
    "                     instances,\n",
    "                     candidate_attribute_indexes,\n",
    "                     target_attribute_index=0,\n",
    "                     default_class=None):\n",
    "        class_labels_and_counts = Counter([instance[target_attribute_index] \n",
    "                                           for instance in instances])\n",
    "        if not instances or not candidate_attribute_indexes:\n",
    "            return default_class\n",
    "        elif len(class_labels_and_counts) == 1:\n",
    "            class_label = class_labels_and_counts.most_common(1)[0][0]\n",
    "            return class_label\n",
    "        else:\n",
    "            default_class = majority_value(instances, target_attribute_index)\n",
    "            best_index = choose_best_attribute_index(instances, \n",
    "                                                               candidate_attribute_indexes, \n",
    "                                                               target_attribute_index)\n",
    "            tree = {best_index:{}}\n",
    "            partitions = split_instances(instances, best_index)\n",
    "            remaining_candidate_attribute_indexes = [i \n",
    "                                                     for i in candidate_attribute_indexes \n",
    "                                                     if i != best_index]\n",
    "            for attribute_value in partitions:\n",
    "                subtree = self._create_tree(\n",
    "                    partitions[attribute_value],\n",
    "                    remaining_candidate_attribute_indexes,\n",
    "                    target_attribute_index,\n",
    "                    default_class)\n",
    "                tree[best_index][attribute_value] = subtree\n",
    "            return tree\n",
    "    \n",
    "    def predict(self, instances, default_class=None):\n",
    "        if not isinstance(instances, list):\n",
    "            return self._predict(self._tree, instance, default_class)\n",
    "        else:\n",
    "            return [self._predict(self._tree, instance, default_class) \n",
    "                    for instance in instances]\n",
    "    \n",
    "    def _predict(self, tree, instance, default_class=None):\n",
    "        if not tree:                                                      # if the node is empty, return the default class\n",
    "            return default_class\n",
    "        if not isinstance(tree, dict):                                    # if the node is a leaf, return its class label\n",
    "            return tree\n",
    "        attribute_index = list(tree.keys())[0]  \n",
    "        attribute_values = list(tree.values())[0]\n",
    "        instance_attribute_value = instance[attribute_index]\n",
    "        if instance_attribute_value not in attribute_values:              # this value was not in training data\n",
    "            return default_class\n",
    "        return self._predict(attribute_values[instance_attribute_value],  # recursively traverse the subtree (branch) associated with instance_attribute_value\n",
    "                             instance,\n",
    "                             default_class)\n",
    "    \n",
    "    def classification_accuracy(self, instances, default_class=None):\n",
    "        predicted_labels = self.predict(instances, default_class)\n",
    "        actual_labels = [x[0] for x in instances]\n",
    "        counts = Counter([x == y for x, y in zip(predicted_labels, actual_labels)])\n",
    "        return counts[True] / len(instances), counts[True], counts[False]\n",
    "    \n",
    "    def pprint(self):\n",
    "        pprint(self._tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: {'a': 'e',\n",
      "     'c': 'p',\n",
      "     'f': 'p',\n",
      "     'l': 'e',\n",
      "     'm': 'p',\n",
      "     'n': {20: {'k': 'e',\n",
      "                'n': 'e',\n",
      "                'r': 'p',\n",
      "                'w': {21: {'c': 'p', 'v': 'e', 'y': 'e'}}}},\n",
      "     'p': 'p'}}\n",
      "\n",
      "Model: p; truth: p\n",
      "Model: p; truth: p\n",
      "Model: p; truth: p\n",
      "Model: e; truth: e\n",
      "Model: e; truth: e\n",
      "Model: p; truth: p\n",
      "Model: e; truth: e\n",
      "Model: e; truth: e\n",
      "Model: e; truth: e\n",
      "Model: p; truth: p\n",
      "Model: e; truth: e\n",
      "Model: e; truth: e\n",
      "Model: e; truth: e\n",
      "Model: p; truth: p\n",
      "Model: e; truth: e\n",
      "Model: e; truth: e\n",
      "Model: e; truth: e\n",
      "Model: e; truth: e\n",
      "Model: p; truth: p\n",
      "Model: p; truth: p\n",
      "\n",
      "Classification accuracy: (1.0, 20, 0)\n"
     ]
    }
   ],
   "source": [
    "UNKNOWN_VALUE = '?'\n",
    "all_instances=load_instances('agaricus_lepiota.txt')\n",
    "clean_instances = [instance\n",
    "                   for instance in all_instances\n",
    "                   if UNKNOWN_VALUE not in instance]\n",
    "\n",
    "\n",
    "training_instances = clean_instances[:-20]\n",
    "test_instances = clean_instances[-20:]\n",
    "simple_decision_tree = SimpleDecisionTree()\n",
    "simple_decision_tree.fit(training_instances)\n",
    "simple_decision_tree.pprint()\n",
    "print()\n",
    "\n",
    "predicted_labels = simple_decision_tree.predict(test_instances)\n",
    "actual_labels = [instance[0] for instance in test_instances]\n",
    "for predicted_label, actual_label in zip(predicted_labels, actual_labels):\n",
    "    print('Model: {}; truth: {}'.format(predicted_label, actual_label))\n",
    "print()\n",
    "print('Classification accuracy:', simple_decision_tree.classification_accuracy(test_instances))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
